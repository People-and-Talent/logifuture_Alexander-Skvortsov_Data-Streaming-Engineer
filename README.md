# Logifuture assignment
This repo contains the code for the assignment for the streaming data engineer position

## How to set up and execute the pipeline

1. From the bash_scripts directory execute: chmod +x create_kafka_topic.sh so that docker-compose has permissions to execute the script
2. Run the docker-compose.yaml with command: `docker compose up -d` in order to set up the services
3. 


## Architecture

For this assignment, I used the below services:

    1. Kafka: As message broker
    2. Spark: To do real time processing

## Assignment task implementation

## Comments



## Examples

## Useful settings